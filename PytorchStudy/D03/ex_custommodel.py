## -------------------------------------------------------------
## 사용자 정의 모델 클래스 
##
## - 부모클래스 : nn.Module
## - 필수메서드 
##   _ _init_ _(self)    : 모델을 구성하는 층(Layer) 객체 생성
##                         필요한 속성 설정 가능
##   forward(self, data) : 순전파 학습 진행 메서드
##                         메서드명 변경 불가
## -------------------------------------------------------------
## 모듈로딩 
## -------------------------------------------------------------
import torch 
import torch.nn as nn 

## -------------------------------------------------------------
## 사용자 정의 모델 클래스 
## -------------------------------------------------------------
## -------------------------------------------------------------
## 모델   설계 : 입력층 + 은닉층 N개 + 출력층 
## 데이터 정의 : 피쳐 6개 int타입, 타겟 1개 float타입
##             입력수    출력수    활성함수
## 입  력  층 :    6        7        ReLU
## 은  닉  층 :    7       10        ReLU
## 출  력  층 :   10        1        회귀/이진분류/다중분류에 따라 다름
##                                   손실함수에 따라 사용 여부 결정
## 타겟이 1개 = 회귀함수이고, 손실함수 사용 x
## 클래스이름: MyModel
## 부모클래스: nn.Mudule
## -------------------------------------------------------------
class MyModel(nn.Module):
    ##- 모델 층 구성 요소 생성 및 초기화
    def __init__(self):
        super().__init__()                  ## 부모 생성
        self.in_layer = nn.Linear(6, 7)     ## 입력층 : 퍼셉트론 7개 
                                            ##         가중치 W가   퍼셉트론마다 6개
                                            ##         바이어스 b가 퍼셉트론마다 1개 
                                            ## out = x1*w1+x2*w2+....+x6*w6 + b

        self.hd_layer = nn.Linear(7, 10)    ## 은닉층 : 퍼셉트론 10개 
                                            ##         가중치 W가   퍼셉트론마다 7개
                                            ##         바이어스 b가 퍼셉트론마다 1개 
                                            #  out = o1*w1+o2*w2+.....+o7*w7+b
                                            #          
        self.ou_layer = nn.Linear(10, 1)    ## 출력층 : 퍼셉트론 1개 
                                            ##         가중치 W가   퍼셉트론마다 10개
                                            ##         바이어스 b가 퍼셉트론마다 1개   
                                            #  out = o1*w1+o2*w2+.....+o10*w10+b
    ##- 순방향 학습 진행 메서드
    def forward(self, data):
        print('learning')
        out=self.in_layer(data)             ## 가중치곱셈의 합계
        out=nn.functional.relu(out)         ## 활성함수 거친 결과

        out=self.hd_layer(out)
        out=nn.functional.relu(out)

        out=self.ou_layer(out)              ## 회귀 즉, 수치값 예측
        return out                          ## 활성함수 사용 X

## -------------------------------------------------------------
## 동작 테스트 
## -------------------------------------------------------------
## - 임의의 데이터 생성
x = torch.tensor([[11,22,33,44,55,66],[15,5432,1,12,46,2],[43,21,75,933,43,2]], dtype=torch.float32)

## - 모델 생성 및 학습 1회
model = MyModel()
## ->모델 클래스의 forward()메서드 실행됨!
out = model(x)

## - 학습 결과
print(f'out =>{out}')

## -------------------------------------------------------------
## 모델 층별 파라미터 즉, 가중치 w,  바이어스 b 확인
## -------------------------------------------------------------
## - 메서드 : 모델변수명.parameters() 
##           모델변수명.named_parameters()  
for name, param in model.named_parameters():
    print(f'[{name}]\n{param}\n')

## -------------------------------------------------------------
## 모델 층별 파라미터 업데이트 즉, 역전파 
## -------------------------------------------------------------
## 최적화 객체 
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# 손실: MSE
loss = ((out - torch.tensor([20,30,40,50,60,70])) ** 2).mean()

# 역전파 및 파라미터 업데이트
optimizer.zero_grad()  # 그래디언트 초기화
loss.backward()        # 기울기 계산
optimizer.step()       # 파라미터 업데이트