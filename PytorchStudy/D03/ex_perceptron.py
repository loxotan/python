## ----------------------------------------------------------
## [ 전결합의 퍼셉트론 ]
## - 입력 데이터와 가중치(weight) 곱셈의 합계 + 절편(bias) 결과를 반환
## - 모든 입력 데이터를 가중치와 곱셈 연산 수행
## - 뉴런의 기본 동작을 코드로 구현
## ----------------------------------------------------------

## ----------------------------------------------------------
## [1] 모듈로딩 및 데이터 준비
## ----------------------------------------------------------
## [1-1] 모듈로딩
import torch                      # 텐서 및 수치함수들 관련 모듈
import torch.nn as nn             # 인공신경망 관련 모듈
import torch.nn.functional as F   # 인공신경망 관렴 함수들 모듈 (AF, LF, MF...)


## [1-2] 데이터 준비
## 랜덤 고정
torch.manual_seed(213)

## 입력 데이터 텐서 생성 
xTS=torch.randint(1, 10, (3, 1)) #1이상 10미만 3행 1열
xTS=xTS.type(torch.float32)

print(f'xTS => {xTS.shape}, {xTS.ndim}, {xTS.dtype}')


## 정답 텐서 생성 
yTS=torch.randint(1, 10, (3, 1))
yTS=yTS.type(torch.float32)

print(f'yTS => {yTS.shape}, {yTS.ndim}, {yTS.dtype}')

## ----------------------------------------------------------
## [2] 가중치와 절편 텐서 생성
## ----------------------------------------------------------
# - 가중치와 절편 텐서 값을 0으로 초기화
# - 퍼셉트론 1개 , 입력 피쳐 1개 , 샘플 3개 
# - 가중치와 절편 텐서 역전파로 업데이트 되어야 함 => requires_grad=True
W = torch.rand(1, requires_grad=True) 
b = torch.rand(1, requires_grad=True) 
print(f'W =>{W}\nb =>{b}')


## ----------------------------------------------------------
## [3] 학습 ==> 입력데이터*가중치 + 절편
## ----------------------------------------------------------
output= xTS * W + b
print(f'output => {output}')

## ----------------------------------------------------------
## [4] 정답과 학습결과 값의 차이 계산 => 손실함수
## ----------------------------------------------------------
# 정답
print("정답", yTS)

# 학습 결과 값
print("결과값", output)

# 정답 - 학습결과값
value=yTS-output
print("차이값", value)

# 차이값 제곱 후 평균 : Mean Square Error MSE 평균제곱오차
value = (yTS-output) ** 2
value = torch.mean(value)
print("MSE", value)